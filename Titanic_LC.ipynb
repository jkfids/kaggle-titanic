{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_LC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei6FwQgd96lu"
      },
      "source": [
        "# Titanic: Machine Learning from Disaster (TensorFlow Linear Classifier)\r\n",
        "\r\n",
        "My first attempt to build a machine learning model to predict the survival of passengers on Kaggle's Titanic competition.\r\n",
        "\r\n",
        "The model implements a linear classifier in TensorFlow.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCwoqmiy3OcM"
      },
      "source": [
        "### Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RVHURKJ3U4V"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lPz83XF3o3h"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3tj2Jjo3q4v"
      },
      "source": [
        "# Construct pandas dataframe from csv files\r\n",
        "dftrain = pd.read_csv('train.csv')\r\n",
        "dfeval = pd.read_csv('test.csv')\r\n",
        "\r\n",
        "# Preprocess the dataframes\r\n",
        "def preprocess(df):\r\n",
        "  #df = df.dropna(subset=['Embarked'])\r\n",
        "  df['Deck'] = df['Cabin'].str.get(0)\r\n",
        "  df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\r\n",
        "  df['Age'] = df['Age'].fillna(df['Age'].mean())\r\n",
        "  df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\r\n",
        "  df['Deck'] = df['Deck'].fillna('M')\r\n",
        "  df['Embarked'] = df['Embarked'].fillna('M')\r\n",
        "  return df\r\n",
        "\r\n",
        "dftrain = preprocess(dftrain)\r\n",
        "y_train = dftrain.pop('Survived')\r\n",
        "\r\n",
        "dfeval = preprocess(dfeval)\r\n",
        "dfeval['Survived'] = np.nan\r\n",
        "y_eval = dfeval.pop('Survived')\r\n",
        "ids = dfeval.pop('PassengerId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOSc4rlKx-zA"
      },
      "source": [
        "dftrain.head(10) # Check the first 10 entries in the training dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTv3ArY_oKj"
      },
      "source": [
        "Plot out statistical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZh5J4lJGRiD"
      },
      "source": [
        "dftrain.Fare.hist(bins=80).set_xlabel('Fare')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diBE_h60GZ67"
      },
      "source": [
        "dftrain.Sex.value_counts().plot(kind='pie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69fkSAfGhyd"
      },
      "source": [
        "dftrain.Pclass.value_counts().plot(kind='pie')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms8m69bxHwQQ"
      },
      "source": [
        "pd.concat([dftrain, y_train], axis=1).groupby('Sex').Survived.mean().plot(kind='barh').set_xlabel('% survive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8noSWVFiS1D8"
      },
      "source": [
        "pd.concat([dftrain, y_train], axis=1).groupby('Embarked').Survived.mean().plot(kind='barh').set_xlabel('% survive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0J5L9DPTAcm"
      },
      "source": [
        "pd.concat([dftrain, y_train], axis=1).groupby('Deck').Survived.mean().plot(kind='barh').set_xlabel('% survive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ8xg_u5JBUV"
      },
      "source": [
        "### Feature Columns\r\n",
        "\r\n",
        "Set up the relevant features that will be used in our linear classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXPu897EJNgU"
      },
      "source": [
        "categorical_columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\r\n",
        "numeric_columns = ['Age', 'Fare']\r\n",
        "\r\n",
        "feature_columns = []\r\n",
        "for feature_name in categorical_columns:\r\n",
        "  vocabulary = dftrain[feature_name].unique()\r\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\r\n",
        "\r\n",
        "for feature_name in numeric_columns:\r\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EvybFGv8bvJ"
      },
      "source": [
        "### Input Function\r\n",
        "\r\n",
        "Constructs input functions out of our dataframes so they may be processed with TensorFlow. The linear classifier uses mini-batch regression, so further expand and process the data by duplicating and shuffling the entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI3wZc2c8fGF"
      },
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\r\n",
        "  def input_function():\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\r\n",
        "    if shuffle:\r\n",
        "      ds = ds.shuffle(1000)\r\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\r\n",
        "    return ds\r\n",
        "  return input_function\r\n",
        "\r\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\r\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t08ZuSrA4As"
      },
      "source": [
        "Train the linear classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEcKslcO6waV"
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\r\n",
        "linear_est.train(input_fn=train_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJFTuFmnA6t7"
      },
      "source": [
        "Make predictions on the test data with our trained linear classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5pJc0bDaLW7"
      },
      "source": [
        "predictions = list(linear_est.predict(eval_input_fn))\r\n",
        "class_list = []\r\n",
        "for pred in predictions:\r\n",
        "  class_list.append(pred['class_ids'][0])\r\n",
        "len(class_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfk3bnNvBI1g"
      },
      "source": [
        "Convert the test dataframe and predictions into a single csv file for submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3YuUECIsM9Y"
      },
      "source": [
        "submission = pd.DataFrame(ids)\r\n",
        "submission['Survived'] = class_list\r\n",
        "submission.reset_index(drop=True)\r\n",
        "submission.to_csv('titanicLC_submission.csv', index=False)\r\n",
        "\r\n",
        "files.download('titanicLC_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}